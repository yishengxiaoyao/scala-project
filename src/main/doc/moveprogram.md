# Hadoop 相关
## 移动计算程序到数据所在位置
移动计算程序到数据所在位置需要的步骤如下:
>* 将待处理的数据存储在Hadoop 集群上，文件会存储到HDFS中，文件是会被分为很多快，以块为单位存储在集群的服务器上。
>* 大数据引擎根据集群里不同服务器的计算能力，在每台服务器上启动若干分布式任务执行进程，这些进程会等待给他们分配执行任务。
>* 使用大数据计算框架支持的变成模型进行编程。
>* 用Hadoop或者Spark的启动命令执行这个应用程序的JAR包，首先执行引擎会解析程序要处理的数据输入路径，根据输入数据量的大小，
将数据分成若干片，每一个数据片都分配给一个任务执行进程去处理。
>* 任务执行进程收到分配的任务后，检查自己是否有任务对应的程序包，如果没有就去下载程序包，下载以后通过反射的方式加载程序。
>* 加载程序后，任务执行顺序根据分配的数据片的文件地址和数据在文件内的偏移量读取数据，并把数据输入给对应程序相应的方法去执行，
从而实现在分布式服务器集群中移动计算程序，对大规模数据进行并行处理的计算目标。

## RAID 技术介绍
RAID技术是将多块普通磁盘组成一个阵列，共同对外提供服务。主要是为了改善磁盘的的存储容量、读写速度，
增加磁盘的可用性和容错能力。
### RAID 0
RAID 0 是数据在内存缓冲区写入磁盘时，根据磁盘数量将数据分成N份，这些数据同时写入N块磁盘，这些数据同时并发写入N块磁盘，
使得数据整体写入速度是一块磁盘的N倍；读取的时候也一样。但是RAID 0不做数据备份，N块磁盘中只要有一块损坏，数据完整性就被
破坏，其他磁盘的数据也都无法使用了。

### RAID 1
RAID 1是数据在写入磁盘时，将一份数据同时写入两块磁盘，这样任何一块磁盘损坏都不会导致数据丢失，插入一块新磁盘就可以
通过复制数据的方式自动修复，具有极高的可靠性。

### RAID 10
RAID 10 将所有磁盘N平均分成两份，数据同时在两份磁盘写入，相当于RAID 1;但是平分成两份，在每一份磁盘里面，利用
RAID 0技术并发读写，这样既提高可靠性有改善性能。不过RAID 10磁盘利用率较低，有一半的磁盘用来写备份数据。

### RAID 5
RAID 5是将数据螺旋式地写入所有的磁盘中。这样校验数据的修改也被平均到所有磁盘上。

|RAID类型|访问速度|数据可靠性|磁盘利用率|
|----|----|----|----|
|RAID0|很快|很低|100%|
|RAID1|很慢|很高|50%|
|RAID10|中等|很高|50%|
|RAID5|较快|较高|(N-1)/N|
|RAID6|较快|较(RAID5)高|(N-2)/N|
实践中使用的RAID10。

## HDFS如何实现大数据高速、可靠的存储和访问
Hadoop 分布式文件系统HDFS的设计目标是管理数以千计的服务器、数以万计的磁盘，将这么大规模的服务器计算资源当作一个
单一的存储系统进行管理，对应用程序提供数以PB级的存储容量，让应用程序像使用普通文件系统一样存储大规模的文件数据。

RAID将数据分片后在多块磁盘上并发进行读写访问，从而提高了存储容量、加快访问速度，并通过数据的冗余校验提高了数据的可靠性，
即使某块磁盘损坏也不会丢失数据。将RAID的设计理念扩大到整个分布式服务器集群，就产生了分布式文件系统，
Hadoop分布式文件系统的核心原理就是如此。

HDFS是在一个大规模分布式服务器集群上，将数据分片后进行并发读写及冗余存储。因此HDFS可以部署在一个比较大的服务器集群上，
集群中所有服务器的磁盘都可供HDFS使用，所以整个HDFS的存储空间可以达到PB级容量。

### HDFS的架构
DataNode负责文件数据的存储和读写操作，HDFS将文件数据分割成若干数据块，每个DataNode存储一部分数据块，这样
文件就分布存储在整个HDFS服务器集群中。应用程序客户端可以并发对这些数据块进行访问，从而使得HDFS可以在服务器集群
规模上实现数据并行访问，极大地提高了访问速度。

NameNode负责整个分布式文件系统的元数据管理，也就是文件路径名、数据块的Id以及存储位置等信息，相当于操作系统中
文件分配表的角色。HDFS的文件数据复制块为3份。

### HDFS高可用设计
#### 数据存储故障容错
HDFS的应对策略是，对于存储在DataNode上的数据块，计算并存储校验和。在读取数据的时候，重新计算读取出来的数据的校验和，
如果校验不正确就抛出异常，应用程序捕获异常后就到其他DataNode上读取备份数据。
#### 磁盘故障容错
如果DataNode检测到本地的某块磁盘损坏，就将该磁盘上存储的所有BlockID报告给NameNode，NameNode检查这些数据块还在哪些
DataNode上有备份，通知相应的DataNode服务器将对应的数据块复制到其他服务器上，以保证数据块的备份数满足要求。

#### DataNode故障容错
DataNode会通过心跳和NameNode保持通信，如果DataNode超时为发送心跳，NameNode就会认为这个DataNode已经宕机失效，
立即查找这个DataNode上存储的数据块有哪些，随后通知这些服务器在复制一份到其他服务器上，保证HDFS存储的数据备份数符合
用户设置的数目。

#### NameNode故障容错
NameNode是整个HDFS的核心，记录着HDFS文件分配表信息，所有的文件路径和数据块存储信息都保存在NameNode，
如果NameNode故障，整个HDFS系统集群都无法使用，如果NameNode上记录的数据丢失，整个集群所有DataNode存储的数据也就没有了
NameNode该可用容错能力非常重要，NameNode采用丛热的方式提供高可用服务。两台服务器通过zookeeper选举，主要是通过争夺znode
锁资源，决定谁是住服务器。DataNode会向两个NameNode同时发送心跳数据，但是只有主NameNode才能向DataNode返回控制信息。

##MapReduce
MapReduce既是一个编程模型，又是一个计算框架。

编程模型只包含Map和Reduce两个过程，map的主要输入是一对<key,value>值，经过map计算后输出一对<key,value>值，
将相同key合并，形成<key,value集合>，再将这个<key,value集合>输入reduce，经过计算输出零个或多个<key,value>对。

以Hadoop 1为例:
JobTracker进程。根据要处理的输入数据量，命令下面提到的TaskTracker进程启动相应数量的Map和Reduce进程任务，
并管理整个作业生命周期的任务调度和监控。这是Hadoop集群的常驻进程，JobTracker进程在整个Hadoop集群全局唯一。

TaskTracker进程。负责启动和管理Map进程以及Reduce进程。因为需要每个数据块都有对应map函数，TaskTracker进程
通常和HDFS的DataNode进程启动在同一个服务器。Hadoop集群中绝大多数服务器同时运行DataNode进程和TaskTracker进程。

MapReduce的主要服务器是JobTracker，从服务器是TaskTracker。

MapReduce框架默认的Partitioner用ket的哈希值对Reduce任务数量取模，相同的key一定会落在相同的Reduce任务ID上。
```
public int getPartition(K2 key,V2 value,int numReduceTask){
    return (key.hashCode()& Integer.MAX_VALUE) % numReduceTask;
}
```
分布式计算需要将不同服务器上的相关数据合并到一起进行下一步计算，这就是shuffle。

MapReduce任务执行过程(以Hadoop 1为例):
1.应用进程JobClient将用户作业JAR包存储在HDFS中，将这些JAR包会分发给Hadoop集群中的服务器执行MapReduce计算。
2.应用程序提交Job作业给JobTracker。
3.JobTracker根据作业调度策略创建JobInProcess树，每个作业都会有一个自己的JobInProcess树。
4.JobInProcess根据输入数据分片数目和设置的Reduce数目创建相应数量的TaskInProcess。
5.TaskTracker进程和JobTracker进程进行定时通信。
6.如果TaskTracker有空闲的计算资源，JobTracker就会给它分配任务。分配任务的时候会根据TaskTracker的服务器名字匹配
子同一台服务器的数据块计算任务给它，使启动的计算任务正好处理本机上的数据。
7.TaskTracker收到任务后根据任务类型和任务参数，启动相应的Map或者Reduce进程。
8.Map或者Reduce进程启动后，检查本地是否有要执行任务的JAR包文件，如果没有，就去HDFS下载，然后加载Map或者Reduce代码开始执行。
9.如果Map进程，从HDFS读取数据;如果是Reduce进程,将结果数据写出到HDFS。


##YARN
Hadoop 1中MapReduce的缺点:
服务器集群资源管理和MapReduce执行过程耦合在一起，如果想在当前集群中运行其他计算任务，就无法统一使用集群中的资源了。

